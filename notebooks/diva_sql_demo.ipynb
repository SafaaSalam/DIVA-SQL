{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02f035e",
   "metadata": {},
   "source": [
    "# DIVA-SQL Framework Demo\n",
    "\n",
    "This notebook demonstrates the key features of the DIVA-SQL framework:\n",
    "- Semantic decomposition of natural language queries\n",
    "- Step-by-step SQL clause generation\n",
    "- In-line verification and error correction\n",
    "- Interpretable query generation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5159b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "from src.core.pipeline import DIVASQLPipeline\n",
    "from src.core.semantic_dag import SemanticDAG, SemanticNode, NodeType\n",
    "from src.utils.error_taxonomy import ErrorTaxonomy, analyze_sql_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad644312",
   "metadata": {},
   "source": [
    "## Setup Mock LLM Client\n",
    "\n",
    "For demonstration purposes, we'll use a mock LLM client that returns predefined responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b80f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockLLMClient:\n",
    "    \"\"\"Mock LLM client for demonstration\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.responses = {\n",
    "            \"decomposition\": {\n",
    "                \"query_type\": \"COUNT\",\n",
    "                \"complexity_indicators\": [\"FILTER\", \"GROUP\", \"JOIN\"],\n",
    "                \"estimated_steps\": 4,\n",
    "                \"reasoning\": \"This query requires filtering, joining, grouping, and counting\"\n",
    "            },\n",
    "            \"components\": {\n",
    "                \"components\": [\n",
    "                    {\n",
    "                        \"type\": \"FILTER\",\n",
    "                        \"description\": \"Filter employees hired after 2022\",\n",
    "                        \"tables\": [\"Employees\"],\n",
    "                        \"columns\": [\"HireDate\"],\n",
    "                        \"priority\": 1\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"JOIN\",\n",
    "                        \"description\": \"Join employees with departments\",\n",
    "                        \"tables\": [\"Employees\", \"Departments\"],\n",
    "                        \"columns\": [\"DeptID\"],\n",
    "                        \"priority\": 2\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"GROUP\",\n",
    "                        \"description\": \"Group by department\",\n",
    "                        \"tables\": [\"Employees\"],\n",
    "                        \"columns\": [\"DeptID\"],\n",
    "                        \"priority\": 3\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"SELECT\",\n",
    "                        \"description\": \"Select department names with count > 10\",\n",
    "                        \"tables\": [\"Departments\"],\n",
    "                        \"columns\": [\"DeptName\"],\n",
    "                        \"priority\": 4\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            \"sql_generation\": {\n",
    "                \"sql_clause\": \"WHERE T1.HireDate > '2022-01-01'\",\n",
    "                \"explanation\": \"Filter for employees hired after 2022\",\n",
    "                \"confidence\": 0.9\n",
    "            },\n",
    "            \"verification\": {\n",
    "                \"is_aligned\": True,\n",
    "                \"issues\": [],\n",
    "                \"confidence\": 0.9\n",
    "            },\n",
    "            \"final_composition\": {\n",
    "                \"final_sql\": \"SELECT T2.DeptName FROM Employees AS T1 JOIN Departments AS T2 ON T1.DeptID = T2.DeptID WHERE T1.HireDate > '2022-01-01' GROUP BY T2.DeptID HAVING COUNT(*) > 10\",\n",
    "                \"confidence\": 0.9\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    class Chat:\n",
    "        def __init__(self, parent):\n",
    "            self.parent = parent\n",
    "        \n",
    "        class Completions:\n",
    "            def __init__(self, parent):\n",
    "                self.parent = parent\n",
    "            \n",
    "            def create(self, **kwargs):\n",
    "                # Determine response type based on prompt content\n",
    "                prompt_content = kwargs.get('messages', [{}])[0].get('content', '')\n",
    "                \n",
    "                if \"structure\" in prompt_content.lower():\n",
    "                    response_data = self.parent.parent.responses[\"decomposition\"]\n",
    "                elif \"components\" in prompt_content.lower():\n",
    "                    response_data = self.parent.parent.responses[\"components\"]\n",
    "                elif \"alignment\" in prompt_content.lower():\n",
    "                    response_data = self.parent.parent.responses[\"verification\"]\n",
    "                elif \"compose\" in prompt_content.lower():\n",
    "                    response_data = self.parent.parent.responses[\"final_composition\"]\n",
    "                else:\n",
    "                    response_data = self.parent.parent.responses[\"sql_generation\"]\n",
    "                \n",
    "                class Response:\n",
    "                    class Choice:\n",
    "                        class Message:\n",
    "                            content = json.dumps(response_data)\n",
    "                    choices = [Choice()]\n",
    "                \n",
    "                return Response()\n",
    "        \n",
    "        def __init__(self, parent):\n",
    "            self.completions = self.Completions(self)\n",
    "            self.parent = parent\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chat = self.Chat(self)\n",
    "\n",
    "# Initialize mock client\n",
    "mock_client = MockLLMClient()\n",
    "print(\"Mock LLM client initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b322eb",
   "metadata": {},
   "source": [
    "## Example 1: Basic DIVA-SQL Pipeline\n",
    "\n",
    "Let's demonstrate the complete DIVA-SQL pipeline with a complex query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3526f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DIVA-SQL pipeline\n",
    "pipeline = DIVASQLPipeline(mock_client, model_name=\"gpt-4\")\n",
    "\n",
    "# Define sample database schema\n",
    "schema = {\n",
    "    \"tables\": {\n",
    "        \"Employees\": [\"EmpID\", \"Name\", \"DeptID\", \"HireDate\", \"Salary\"],\n",
    "        \"Departments\": [\"DeptID\", \"DeptName\", \"ManagerID\"],\n",
    "        \"Projects\": [\"ProjectID\", \"ProjectName\", \"Budget\", \"DeptID\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Complex natural language query\n",
    "nl_query = \"What are the names of departments with more than 10 employees hired after 2022?\"\n",
    "\n",
    "print(f\"Natural Language Query: {nl_query}\")\n",
    "print(f\"Database Schema: {json.dumps(schema, indent=2)}\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SQL using DIVA-SQL\n",
    "result = pipeline.generate_sql(nl_query, schema)\n",
    "\n",
    "print(\"DIVA-SQL Results:\")\n",
    "print(f\"Status: {result.status.value}\")\n",
    "print(f\"Execution Time: {result.execution_time:.2f} seconds\")\n",
    "print(f\"Confidence Score: {result.confidence_score:.2f}\")\n",
    "print(f\"\\nGenerated SQL:\")\n",
    "print(result.final_sql)\n",
    "\n",
    "if result.semantic_dag:\n",
    "    print(f\"\\nSemantic Decomposition:\")\n",
    "    print(result.semantic_dag.visualize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4aaaac",
   "metadata": {},
   "source": [
    "## Example 2: Semantic DAG Visualization\n",
    "\n",
    "Let's create and visualize a semantic DAG manually to understand the decomposition process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a semantic DAG manually for educational purposes\n",
    "dag = SemanticDAG(\"demo_query\")\n",
    "\n",
    "# Node 1: Filter employees by hire date\n",
    "filter_node = SemanticNode(\n",
    "    id=\"filter_employees\",\n",
    "    node_type=NodeType.FILTER,\n",
    "    description=\"Filter employees hired after 2022\",\n",
    "    tables=[\"Employees\"],\n",
    "    columns=[\"HireDate\"],\n",
    "    conditions=[\"HireDate > '2022-01-01'\"]\n",
    ")\n",
    "\n",
    "# Node 2: Join with departments\n",
    "join_node = SemanticNode(\n",
    "    id=\"join_departments\",\n",
    "    node_type=NodeType.JOIN,\n",
    "    description=\"Join employees with departments\",\n",
    "    tables=[\"Employees\", \"Departments\"],\n",
    "    columns=[\"DeptID\"]\n",
    ")\n",
    "\n",
    "# Node 3: Group by department\n",
    "group_node = SemanticNode(\n",
    "    id=\"group_by_dept\",\n",
    "    node_type=NodeType.GROUP,\n",
    "    description=\"Group employees by department\",\n",
    "    tables=[\"Employees\"],\n",
    "    columns=[\"DeptID\"]\n",
    ")\n",
    "\n",
    "# Node 4: Filter departments with count > 10\n",
    "having_node = SemanticNode(\n",
    "    id=\"filter_count\",\n",
    "    node_type=NodeType.HAVING,\n",
    "    description=\"Keep departments with more than 10 employees\",\n",
    "    conditions=[\"COUNT(*) > 10\"]\n",
    ")\n",
    "\n",
    "# Node 5: Select department names\n",
    "select_node = SemanticNode(\n",
    "    id=\"select_names\",\n",
    "    node_type=NodeType.SELECT,\n",
    "    description=\"Select department names\",\n",
    "    tables=[\"Departments\"],\n",
    "    columns=[\"DeptName\"]\n",
    ")\n",
    "\n",
    "# Add nodes to DAG\n",
    "for node in [filter_node, join_node, group_node, having_node, select_node]:\n",
    "    dag.add_node(node)\n",
    "\n",
    "# Add dependencies (execution order)\n",
    "dag.add_edge(\"filter_employees\", \"join_departments\")\n",
    "dag.add_edge(\"join_departments\", \"group_by_dept\")\n",
    "dag.add_edge(\"group_by_dept\", \"filter_count\")\n",
    "dag.add_edge(\"filter_count\", \"select_names\")\n",
    "\n",
    "print(\"Manual Semantic DAG:\")\n",
    "print(dag.visualize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f1f25c",
   "metadata": {},
   "source": [
    "## Example 3: Error Taxonomy Demonstration\n",
    "\n",
    "Let's explore the error taxonomy system that helps detect common SQL errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d0c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize error taxonomy\n",
    "taxonomy = ErrorTaxonomy()\n",
    "\n",
    "# Show taxonomy summary\n",
    "summary = taxonomy.get_taxonomy_summary()\n",
    "print(\"Error Taxonomy Summary:\")\n",
    "print(f\"Total Error Patterns: {summary['total_patterns']}\")\n",
    "print(f\"Categories: {list(summary['categories'].keys())}\")\n",
    "print(f\"Severity Distribution: {summary['severity_distribution']}\")\n",
    "\n",
    "print(\"\\nMost Common Error Categories:\")\n",
    "for category, count in summary['most_common_categories']:\n",
    "    print(f\"  {category}: {count} patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e067e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error detection on problematic SQL\n",
    "problematic_sql = \"SELECT Name, COUNT(*) FROM Employee WHERE EmpID = '123'\"\n",
    "\n",
    "print(f\"Analyzing SQL: {problematic_sql}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "analysis = analyze_sql_errors(problematic_sql, taxonomy)\n",
    "\n",
    "print(f\"Issues Found: {analysis['total_issues']}\")\n",
    "print(f\"Risk Score: {analysis['risk_score']}\")\n",
    "print(f\"Categories Affected: {analysis['categories_affected']}\")\n",
    "print(\"\\nDetailed Issues:\")\n",
    "\n",
    "for pattern in analysis['patterns_matched']:\n",
    "    print(f\"  - {pattern['name']} ({pattern['severity']})\")\n",
    "    print(f\"    {pattern['description']}\")\n",
    "    print(f\"    Fix: {pattern['suggested_fix']}\")\n",
    "    print()\n",
    "\n",
    "print(\"Recommendations:\")\n",
    "for rec in analysis['recommended_actions']:\n",
    "    print(f\"  {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90304be8",
   "metadata": {},
   "source": [
    "## Example 4: Verification Process Simulation\n",
    "\n",
    "Let's simulate the verification process that DIVA-SQL uses to check generated SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa6a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.verifier import VerificationAgent, VerificationStatus\n",
    "\n",
    "# Initialize verification agent\n",
    "verifier = VerificationAgent(mock_client)\n",
    "\n",
    "# Test SQL clause\n",
    "test_sql = \"WHERE T1.HireDate > '2022-01-01'\"\n",
    "\n",
    "# Create corresponding semantic node\n",
    "test_node = SemanticNode(\n",
    "    id=\"test_filter\",\n",
    "    node_type=NodeType.FILTER,\n",
    "    description=\"Filter employees hired after 2022\",\n",
    "    tables=[\"Employees\"],\n",
    "    columns=[\"HireDate\"]\n",
    ")\n",
    "\n",
    "print(f\"Testing SQL Clause: {test_sql}\")\n",
    "print(f\"Semantic Intent: {test_node.description}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Verify the clause\n",
    "verification_result = verifier.verify_clause(test_node, test_sql, schema)\n",
    "\n",
    "print(f\"Verification Status: {verification_result.status.value}\")\n",
    "print(f\"Confidence: {verification_result.confidence:.2f}\")\n",
    "print(f\"Issues Found: {len(verification_result.issues)}\")\n",
    "\n",
    "if verification_result.detailed_feedback:\n",
    "    print(f\"\\nDetailed Feedback:\")\n",
    "    print(verification_result.detailed_feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc38b0",
   "metadata": {},
   "source": [
    "## Example 5: Comparing Multiple Queries\n",
    "\n",
    "Let's process multiple queries to see how DIVA-SQL handles different complexity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad865ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test queries of varying complexity\n",
    "test_queries = [\n",
    "    \"Show me all employee names\",\n",
    "    \"How many employees are in each department?\",\n",
    "    \"Which departments have more than 5 employees?\",\n",
    "    \"What is the average salary of employees hired after 2020 by department?\",\n",
    "    \"Find departments with the highest average salary among employees hired in the last 2 years\"\n",
    "]\n",
    "\n",
    "print(\"Processing Multiple Queries:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\nQuery {i}: {query}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Process with DIVA-SQL\n",
    "    result = pipeline.generate_sql(query, schema)\n",
    "    \n",
    "    print(f\"Status: {result.status.value}\")\n",
    "    print(f\"Generated SQL: {result.final_sql}\")\n",
    "    print(f\"Confidence: {result.confidence_score:.2f}\")\n",
    "    print(f\"Time: {result.execution_time:.2f}s\")\n",
    "    \n",
    "    if result.semantic_dag:\n",
    "        node_count = len(result.semantic_dag.nodes)\n",
    "        print(f\"Semantic Nodes: {node_count}\")\n",
    "        \n",
    "        # Show the semantic steps\n",
    "        print(\"Steps:\")\n",
    "        for node_id, node in result.semantic_dag.nodes.items():\n",
    "            print(f\"  - {node.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce80918",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This demo showcased the key features of DIVA-SQL:\n",
    "\n",
    "1. **Semantic Decomposition**: Breaking complex queries into interpretable steps\n",
    "2. **Stepwise Generation**: Creating SQL clauses for individual semantic operations\n",
    "3. **In-line Verification**: Checking each clause before composition\n",
    "4. **Error Detection**: Using comprehensive taxonomy to identify common mistakes\n",
    "5. **Interpretability**: Providing clear visibility into the reasoning process\n",
    "\n",
    "These capabilities make DIVA-SQL more reliable, debuggable, and trustworthy compared to traditional monolithic Text-to-SQL approaches."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
